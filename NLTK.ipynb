{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### NLTK Tutorial\n",
    "\n",
    "NLTK is literally an acronym for Natural Language Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install NLTK with Python 3.x using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Tokenize words\n",
    "A sentence or data can be split into words using the method **word_tokenize()**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing sentences\n",
    "The same principle can be applied to sentences. Simply change the to **sent_tokenize()**\n",
    "We have added two sentences to the variable data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All work and no play makes jack dull boy.', 'All work and no play makes jack a dull boy.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "print(sent_tokenize(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK and arrays\n",
    "If you wish to you can store the words and sentences in arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All work and no play makes jack dull boy.', 'All work and no play makes jack a dull boy.']\n",
      "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    " \n",
    "phrases = sent_tokenize(data)\n",
    "words = word_tokenize(data)\n",
    " \n",
    "print(phrases)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing: remove stop words\n",
    "#### NLTK stop words\n",
    "NLTK Natural Language Processing with Python\n",
    "Natural language processing (nlp) is a research field that presents many challenges such as natural language understanding.\n",
    "Text may contain stop words like ‘the’, ‘is’, ‘are’. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words.\n",
    "\n",
    "In this article you will learn how to remove stop words with the nltk module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english'))\n",
    "words = word_tokenize(data)\n",
    "wordsFiltered = []\n",
    " \n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    " \n",
    "print(wordsFiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       All\n",
      "1      work\n",
      "4      play\n",
      "5     makes\n",
      "6      jack\n",
      "7      dull\n",
      "8       boy\n",
      "9         .\n",
      "10      All\n",
      "11     work\n",
      "14     play\n",
      "15    makes\n",
      "16     jack\n",
      "18     dull\n",
      "19      boy\n",
      "20        .\n",
      "Name: word, dtype: object\n",
      "2     and\n",
      "3      no\n",
      "12    and\n",
      "13     no\n",
      "17      a\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Table1 = pd.DataFrame(words,columns=['word'])\n",
    "                  \n",
    "\n",
    "Table2=pd.DataFrame.transpose(pd.DataFrame([stopWords]))\n",
    "\n",
    "Table2.columns = ['word']\n",
    "\n",
    "index=Table1.word.isin(Table2.word) \n",
    "\n",
    "print(Table1.word[index==False])\n",
    "\n",
    "print(Table1.word[index==True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TableA = pd.DataFrame(np.random.rand(4, 3),\n",
    "                      pd.Index(list('abcd'), name='Key'),\n",
    "                      ['A', 'B', 'C']).reset_index()\n",
    "TableB = pd.DataFrame(np.random.rand(4, 3),\n",
    "                      pd.Index(list('aecf'), name='Key'),\n",
    "                      ['A', 'B', 'C']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.801643</td>\n",
       "      <td>0.605580</td>\n",
       "      <td>0.796524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>0.155228</td>\n",
       "      <td>0.760834</td>\n",
       "      <td>0.669480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>0.853515</td>\n",
       "      <td>0.961704</td>\n",
       "      <td>0.513742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>0.501308</td>\n",
       "      <td>0.187677</td>\n",
       "      <td>0.057073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Key         A         B         C\n",
       "0   a  0.801643  0.605580  0.796524\n",
       "1   e  0.155228  0.760834  0.669480\n",
       "2   c  0.853515  0.961704  0.513742\n",
       "3   f  0.501308  0.187677  0.057073"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TableB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.379867</td>\n",
       "      <td>0.953032</td>\n",
       "      <td>0.971827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>0.923072</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.927991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>0.630206</td>\n",
       "      <td>0.362749</td>\n",
       "      <td>0.886373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>0.106573</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.990087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Key         A         B         C\n",
       "0   a  0.379867  0.953032  0.971827\n",
       "1   b  0.923072  0.011723  0.927991\n",
       "2   c  0.630206  0.362749  0.886373\n",
       "3   d  0.106573  0.519791  0.990087"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TableA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e', 'f'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify what values are in TableB and not in TableA\n",
    "key_diff = set(TableB.Key).difference(TableA.Key)\n",
    "key_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3     True\n",
       "Name: Key, dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_diff = TableB.Key.isin(key_diff)\n",
    "where_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "2    c\n",
       "Name: Key, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=TableB.Key.isin(TableA.Key) \n",
    "\n",
    "TableB.Key[index==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.379867</td>\n",
       "      <td>0.953032</td>\n",
       "      <td>0.971827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>0.923072</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.927991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>0.630206</td>\n",
       "      <td>0.362749</td>\n",
       "      <td>0.886373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>0.106573</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.990087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0.155228</td>\n",
       "      <td>0.760834</td>\n",
       "      <td>0.669480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>0.501308</td>\n",
       "      <td>0.187677</td>\n",
       "      <td>0.057073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Key         A         B         C\n",
       "0   a  0.379867  0.953032  0.971827\n",
       "1   b  0.923072  0.011723  0.927991\n",
       "2   c  0.630206  0.362749  0.886373\n",
       "3   d  0.106573  0.519791  0.990087\n",
       "4   e  0.155228  0.760834  0.669480\n",
       "5   f  0.501308  0.187677  0.057073"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice TableB accordingly and append to TableA\n",
    "TableA.append(TableB[where_diff], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003781184001127258"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2\n",
    "import timeit\n",
    "\n",
    "start=timeit.default_timer()\n",
    "\n",
    "rows = []\n",
    "for i, row in TableB.iterrows():\n",
    "    if row.Key not in TableA.Key.values:\n",
    "        rows.append(row)\n",
    "\n",
    "pd.concat([TableA.T] + rows, axis=1).T\n",
    "\n",
    "end=timeit.default_timer()\n",
    "end - start #elapsed time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x110929fc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TableB.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableB_only\n",
      "  Key  A_foo  B_foo  C_foo         A         B         C      _merge\n",
      "4   e    NaN    NaN    NaN  0.155228  0.760834  0.669480  right_only\n",
      "5   f    NaN    NaN    NaN  0.501308  0.187677  0.057073  right_only\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.379867</td>\n",
       "      <td>0.953032</td>\n",
       "      <td>0.971827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>0.923072</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.927991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>0.630206</td>\n",
       "      <td>0.362749</td>\n",
       "      <td>0.886373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>0.106573</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.990087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0.155228</td>\n",
       "      <td>0.760834</td>\n",
       "      <td>0.669480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>0.501308</td>\n",
       "      <td>0.187677</td>\n",
       "      <td>0.057073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Key         A         B         C\n",
       "0   a  0.379867  0.953032  0.971827\n",
       "1   b  0.923072  0.011723  0.927991\n",
       "2   c  0.630206  0.362749  0.886373\n",
       "3   d  0.106573  0.519791  0.990087\n",
       "4   e  0.155228  0.760834  0.669480\n",
       "5   f  0.501308  0.187677  0.057073"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method three\n",
    "TableB_only = pd.merge(\n",
    "    TableA, TableB,\n",
    "    how='outer', on='Key', indicator=True, suffixes=('_foo','')).query(\n",
    "        '_merge == \"right_only\"')\n",
    "\n",
    "print('TableB_only', TableB_only, sep='\\n')\n",
    "\n",
    "Table_concatenated = pd.concat((TableA, TableB_only), join='inner')\n",
    "\n",
    "Table_concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK – stemming\n",
    "A word stem is part of a word. It is sort of a normalization idea, but linguistic.\n",
    "For example, the stem of the word waiting is wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game\n",
      "game\n",
      "game\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "words = [\"game\",\"gaming\",\"gamed\",\"games\"]\n",
    "ps = PorterStemmer()\n",
    " \n",
    "for word in words:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do word stemming for sentences too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaming:game\n",
      ",:,\n",
      "the:the\n",
      "gamers:gamer\n",
      "play:play\n",
      "games:game\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "ps = PorterStemmer()\n",
    " \n",
    "sentence = \"gaming, the gamers play games\"\n",
    "words = word_tokenize(sentence)\n",
    " \n",
    "for word in words:\n",
    "    print(word + \":\" + ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gaming', ',', 'the', 'gamers', 'play', 'games']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK speech tagging\n",
    "\n",
    "The module NLTK can automatically tag speech.\n",
    "Given a sentence or paragraph, it can label words such as verbs, nouns and so on.\n",
    "\n",
    "NLTK – speech tagging example\n",
    "\n",
    "The example below automatically tags words with a corresponding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Whether', 'IN'), ('you', 'PRP'), (\"'re\", 'VBP'), ('new', 'JJ'), ('to', 'TO'), ('programming', 'VBG'), ('or', 'CC'), ('an', 'DT'), ('experienced', 'JJ'), ('developer', 'NN'), (',', ','), ('it', 'PRP'), (\"'s\", 'VBZ'), ('easy', 'JJ'), ('to', 'TO'), ('learn', 'VB'), ('and', 'CC'), ('use', 'VB'), ('Python', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    " \n",
    "document = 'Whether you\\'re new to programming or an experienced developer, it\\'s easy to learn and use Python.'\n",
    "sentences = nltk.sent_tokenize(document)   \n",
    "for sent in sentences:\n",
    "    print(nltk.pos_tag(nltk.word_tokenize(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter this data based on the type of word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Netherlands', 'NNP')\n",
      "('King', 'NNP')\n",
      "('Day', 'NNP')\n",
      "('San', 'NNP')\n",
      "('Francisco', 'NNP')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    " \n",
    "document = 'Today the Netherlands celebrates King\\'s Day. To honor this tradition, the Dutch embassy in San Francisco invited me to'\n",
    "sentences = nltk.sent_tokenize(document)   \n",
    " \n",
    "data = []\n",
    "for sent in sentences:\n",
    "    data = data + nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "for word in data: \n",
    "    if 'NNP' in word[1]: \n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Language Processing – prediction\n",
    "\n",
    "#### NLTK\n",
    "Natural Language Processing with Python\n",
    "We can use natural language processing to make predictions.\n",
    "Example: Given a product review, a computer can predict if its positive or negative based on the text.\n",
    "\n",
    "In this article you will learn how to make a prediction program based on natural language processing.\n",
    "\n",
    "nlp prediction example\n",
    "\n",
    "Given a name, the classifier will predict if it’s a male or female.\n",
    "\n",
    "To create our analysis program, we have several steps:\n",
    "\n",
    "Data preparation\n",
    "Feature extraction\n",
    "Training\n",
    "Prediction\n",
    "Data preparation\n",
    "The first step is to prepare data.\n",
    "We use the names set included with nltk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    " \n",
    "# Load data and training \n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "\t [(name, 'female') for name in names.words('female.txt')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is simply a collection of tuples. To give you an idea of what the dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zorana', 'female'), ('Zorina', 'female'), ('Zorine', 'female')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(u'Aaron', 'male'), (u'Abbey', 'male'), (u'Abbie', 'male')]\n",
    "[(u'Zorana', 'female'), (u'Zorina', 'female'), (u'Zorine', 'female')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define your own set of tuples if you wish, its simply a list containing many tuples.\n",
    "\n",
    "Feature extraction\n",
    "Based on the dataset, we prepare our feature. The feature we will use is the last letter of a name:\n",
    "We define a featureset using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gender_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-30bb6123112b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturesets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-30bb6123112b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturesets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gender_features' is not defined"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the features (last letters) are extracted using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word): \n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and prediction\n",
    "We train and predict using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "print(classifier.classify(gender_features('Frank')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "A classifier has a training and a test phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    " \n",
    "def gender_features(word): \n",
    "    return {'last_letter': word[-1]} \n",
    " \n",
    "# Load data and training \n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "\t [(name, 'female') for name in names.words('female.txt')])\n",
    " \n",
    "featuresets = [(gender_features(n), g) for (n,g) in names] \n",
    "train_set = featuresets\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "print(classifier.classify(gender_features('Frank')))\n",
    "\n",
    "print(classifier.classify(gender_features('Alex')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "If you want to give the name during runtime, change the last line to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "name = input(\"Name: \")\n",
    "print(classifier.classify(gender_features(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Sentiment Analysis\n",
    "\n",
    "#### Sentiment Analysis\n",
    "\n",
    "In Natural Language Processing there is a concept known as Sentiment Analysis.\n",
    "\n",
    "Given a movie review or a tweet, it can be automatically classified in categories.\n",
    "These categories can be user defined (positive, negative) or whichever classes you want.\n",
    "\n",
    "#### Sentiment Analysis Example\n",
    "\n",
    "Classification is done using several steps: training and prediction.\n",
    "\n",
    "The training phase needs to have training data, this is example data in which we define examples. The classifier will use the training data to make predictions.\n",
    "\n",
    "We start by defining 3 classes: positive, negative and neutral.\n",
    "Each of these is defined by a vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every word is converted into a feature using a simplified bag of words model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set is then the sum of these three feature sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = negative_features + positive_features + neutral_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make predictions.\n",
    "\n",
    "##### Code example\n",
    "This example classifies sentences according to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]\n",
    " \n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
    " \n",
    "train_set = negative_features + positive_features + neutral_features\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "neg = 0\n",
    "pos = 0\n",
    "sentence = \"Awesome movie, I liked it\"\n",
    "sentence = sentence.lower()\n",
    "words = sentence.split(' ')\n",
    "for word in words:\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "print('Negative: ' + str(float(neg)/len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
